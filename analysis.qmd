---
title: Analysis
description: Here we provide a detailed analysis using more sophisticated statistics techniques.
toc: true
draft: false
---

![](images/college_scorecard.png)

This comes from the file `analysis.qmd`.

## Motivation Behind Data Analysis
#### Variables and Relationships of Interest

This analysis aims to investigate the relationships between traditional predictors of success, assessed prior to college, and academic indicators of success, measured post-college, with a focus on the moderating effect of racial demographics.

#### Key Questions

1. How do academic indicators of success — completion rates, post-college earnings, and median student loan debt — vary across racial groups and the racial composition of schools?

2. Does there exist a relationship between traditional predictors of academic success, such as SAT scores and the prestige of universities (measured by acceptance rate percentages) and post-college earnings?
```{r}
suppressWarnings(suppressMessages(library(tidyverse)))
suppressWarnings(suppressMessages(library(ggplot2)))
suppressWarnings(suppressMessages(library(readr)))
suppressWarnings(suppressMessages(library(dplyr)))
suppressWarnings(suppressMessages(library(scales)))
```

## 1. Initial Analysis of Race-Based Completion Rates Across Massachusetts Universities 
```{r}
education_data <- read_rds("dataset/education_cohort_data_cleaned.rds") |>
  filter(State == "CA") |>
  pivot_longer(cols = c(White_Compl_Rate, Black_Compl_Rate, Hisp_Compl_Rate, 
                        Asian_Compl_Rate),
               names_to = "Race", values_to = "Completion_Rate")

ggplot(education_data, aes(x = Completion_Rate, y = Race)) +
  geom_point(aes(color = Race), size = 2, alpha = 0.49) + 
  stat_summary(aes(x = Completion_Rate, y = Race), 
               fun = mean, geom = "point", size = 4, color = "black", alpha = 0.4) +  # Mean as larger black dots
  labs(title = "Completion Rates Across Universities by Race",
       subtitle = "Each data value represents each universities' completion rates",
       x = "Completion Rate",
       y = "") +
  theme_minimal() +
  scale_color_viridis_d() +
  theme(legend.position = "none") 
```
```{r}
library(ggplot2)
library(tidyr)
#library(viridis)

# Assuming education_data is already loaded and pivoted
education_data_longer <- read_rds("dataset/education_cohort_data_cleaned.rds") |>
  pivot_longer(cols = c(White_Compl_Rate, Black_Compl_Rate, Hisp_Compl_Rate, 
                        Asian_Compl_Rate, Two_Or_More_Races_Compl_Rate),
               names_to = "Race", values_to = "Completion_Rate")

# Create the density plot
ggplot(education_data_longer, aes(x = Completion_Rate, fill = Race)) +
  geom_density(alpha = 0.6) +  # density plot with transparency
  labs(title = "Completion Rates Across Universities by Race",
       subtitle = "Density plot showing the distribution of completion rates",
       x = "Completion Rate",
       y = "Density") +
  theme_minimal() 

```




```{r}
# look at each individual institution and determine: how do median earnings differ based off of race?
# take each college and look at which race is the highest percentage
# look at med earnings 6-10 years after college and average it

# We read data and filter for institutions in Massachusetts
#ma_data <- read_rds("dataset/education_cohort_data_cleaned.rds") #|>
  #filter(State == "MA")

# create a dominant race col in education table to identify highest percentage race at university
education_data <- read_rds("dataset/education_cohort_data_cleaned.rds")
education_data$Highest_Perc_Race <- apply(
  education_data[, c("Perc_Undergrad_White", "Perc_Undergrad_Black", "Perc_Undergrad_Hispanic",
              "Perc_Undergrad_Asian", "Perc_Two_Or_More_Races")], 1,
  function(x) c("White", "Black", "Hispanic", "Asian", "Two_Or_More")[which.max(x)]
)

# create a median earnings column, converting from character to numeric data type
earnings_columns <- c("Med_earnings_After_6_Years", "Med_earnings_After_7_Years", 
                      "Med_earnings_After_8_Years", "Med_earnings_After_9_Years", 
                      "Med_earnings_After_10_Years")

education_data[, earnings_columns] <- lapply(education_data[, earnings_columns], function(x) as.numeric(as.character(x)))

education_data$Avg_Med_Earnings <- rowMeans(
  education_data[, earnings_columns],
  na.rm = TRUE
)

# put together our graph that has individual box and whisker plots for each dominant race
ggplot(education_data, aes(x = Highest_Perc_Race, y = Avg_Med_Earnings, color = Highest_Perc_Race)) +
  geom_boxplot() +
  scale_fill_brewer(palette = "Set1") + 
  labs(
    title = "Average Student Median Earnings Across US Institutions",
    x = "Dominant Race Population for Institution",
    y = "Average Median Earnings"
  ) + scale_y_continuous(labels = label_comma(scale = 1)) +
  theme_minimal() +
  theme(legend.position = "none")

education_data


# take levels of income inequality and compare to 

# at more expensive universities what is racial divide?

# take a similar model with dominant race population for each institution and median loan debt.

```



```{r}

library(ggplot2)
library(dplyr)   # For data manipulation
library(scales)  # For number formatting


# Create 10 bins for Socioeconomic_Div: 0-10%, 10-20%, 20-30%, ..., 90-100%
education_data$Socioeconomic_Bins <- cut(education_data$Socioeconomic_Div, 
                                          breaks = seq(0, 1, by = .1),  # 10% intervals (0-10, 10-20, ..., 90-100)
                                          labels = paste(seq(0, 0.9, by = .1), "-", seq(.1, 1, by = .1)),
                                          right = FALSE)

# Calculate average median earnings for each bin
average_earnings_by_bin <- education_data %>%
  group_by(Socioeconomic_Bins) %>%
  summarise(Avg_Med_Earnings = mean(Avg_Med_Earnings, na.rm = TRUE))

# Create the bar plot
ggplot(average_earnings_by_bin, aes(x = Socioeconomic_Bins, y = Avg_Med_Earnings, fill = Socioeconomic_Bins)) +
  geom_col() + 
  #geom_col(fill = "skyblue") +  # Use geom_col for actual values (average earnings)
  scale_y_continuous(labels = label_comma(scale = 1)) +  # Format y-axis labels with commas
  labs(
    title = "Average Median Earnings by Percent Socioeconomic Diversity",
    x = "Socioeconomic Diversity",
    y = "Average Median Earnings"
  ) +
  # scale_fill_viridis_d() + 
  scale_fill_brewer(palette = "Set2") +
  theme_minimal() +
  theme(legend.position = "none")

```



```{r}
library(ggplot2)
library(dplyr)

# Create a new variable to check the dominant race
education_data$Highest_Perc_Race <- apply(
  education_data[, c("Perc_Undergrad_White", "Perc_Undergrad_Black", "Perc_Undergrad_Hispanic", "Perc_Undergrad_Asian")], 
  1, 
  function(x) c("White", "Black", "Hispanic", "Asian")[which.max(x)]
)

# Filter out data for institutions where race is one of White, Black, Asian, Hispanic and tuition is not NA
education_data_long <- education_data %>%
  filter(!is.na(Average_Cost_Of_Attendance)) %>%
  filter(Highest_Perc_Race %in% c("White", "Black", "Hispanic", "Asian"))

# Create the density plot for all races, overlaying the plots
ggplot(education_data_long, aes(x = Average_Cost_Of_Attendance, fill = Highest_Perc_Race)) +
  geom_density(alpha = 0.3) +  # Density plot with transparent fill
  labs(
    title = "Probability Density of Tuition for Institutions by Dominant Race",
    x = "Average Cost of Attendance (Tuition)",
    y = "Density"
  ) +
  scale_fill_brewer(palette = "Set1") +  # Color palette for races
  scale_y_continuous(labels = scales::label_comma(scale = 1)) +  # Formatting Y-axis labels for readability
  theme_minimal() +
  theme(legend.title = element_blank())  # Remove legend title




```


We describe here our detailed data analysis. This page will provide an overview of what questions you addressed, illustrations of relevant aspects of the data with tables and figures, and a statistical model that attempts to answer part of the question. You'll also reflect on next steps and further analysis.

The audience for this page is someone like your class mates, so you can expect that they have some level of statistical and quantitative sophistication and understand ideas like linear and logistic regression, coefficients, confidence intervals, overfitting, etc. 

While the exact number of figures and tables will vary and depend on your analysis, you should target around 5 to 6. An overly long analysis could lead to losing points.
If you want you can link back to your blog posts or create separate pages with more details.

The style of this paper should aim to be that of an academic paper. 
I don't expect this to be of publication quality but you should keep that aim in mind.
Avoid using "we" too frequently, for example "We also found that ...". Describe your methodology and your findings but don't describe your whole process.

### Example of loading data

The code below shows an example of loading the loan refusal data set (which you should delete at some point).

```{r}
library(tidyverse)
print(getwd())
data <- read_rds(here::here("dataset/loan_refusal_clean.rds"))
```

## Note on Attribution

In general, you should try to provide links to relevant resources, especially those that helped you. You don't have to link to every StackOverflow post you used but if there are explainers on aspects of the data or specific models that you found helpful, try to link to those. Also, try to link to other sources that might support (or refute) your analysis. These can just be regular hyperlinks. You don't need a formal citation.

If you are directly quoting from a source, please make that clear. You can show quotes using `>` like this

```         
> To be or not to be.
```

> To be or not to be.

------------------------------------------------------------------------

## Rubric: On this page

You will

-   Introduce what motivates your Data Analysis (DA)
    -   Which variables and relationships are you most interested in?
    -   What questions are you interested in answering?
    -   Provide context for the rest of the page. This will include figures/tables that illustrate aspects of the data of your question.
-   Modeling and Inference
    -   The page will include some kind of formal statistical model. This could be a linear regression, logistic regression, or another modeling framework.
    -   Explain the ideas and techniques you used to choose the predictors for your model. (Think about including interaction terms and other transformations of your variables.)
    -   Describe the results of your modelling and make sure to give a sense of the uncertainty in your estimates and conclusions.
-   Explain the flaws and limitations of your analysis
    -   Are there some assumptions that you needed to make that might not hold? Is there other data that would help to answer your questions?
-   Clarity Figures
    -   Are your figures/tables/results easy to read, informative, without problems like overplotting, hard-to-read labels, etc?
    -   Each figure should provide a key insight. Too many figures or other data summaries can detract from this. (While not a hard limit, around 5 total figures is probably a good target.)
    -   Default `lm` output and plots are typically not acceptable.
-   Clarity of Explanations
    -   How well do you explain each figure/result?
    -   Do you provide interpretations that suggest further analysis or explanations for observed phenomenon?
-   Organization and cleanliness.
    -   Make sure to remove excessive warnings, hide most or all code, organize with sections or multiple pages, use bullets, etc.
    -   This page should be self-contained, i.e. provide a description of the relevant data.
